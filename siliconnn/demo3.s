/**
 * Reference implementation: https://github.com/brandon-gong/siliconnn/blob/main/ref_impl/demo3.c
 *
 * Demo 3: Loading saved network from demo.nn, and using it to run predictions
 * on Iris data.
 */

.global _main
.align 2

// Stack memory layout:
// [SP + 0]: return address
// [SP + 8]: Space for neural network
// [SP + 72]: Stores i, the iterator for the for loops
// [SP + 80]: Buffer for printing predictions, used by dtoa
// Note we don't load a dataset at all this time!
_main:
	SUB SP, SP, #112           // Allocate space on stack per above
	STR LR, [SP]               // Store return address into [SP + 0]

	BL _seed                   // Seed the random number generator

	// Instead of calling nn_init to get a random, untrained network, we simply
	// call nn_load to load the fully trained network from the file. Everything
	// is stored there; we don't need to remember the input size, hidden layer
	// size, or learning rate.
	ADD X0, SP, #8             // First argument to nn_load: ptr to space for net
	ADR X1, load_path          // Second argument: path to the saved demo.nn file
	BL _nn_load                // Load the pretrained net generated by demo2

	// We will run predictions on three test examples, and print the net's
	// predictions out to stdout. First, we print a little label, just
	// "Predictions:", so the user knows the next numbers we print are the net's
	// predictions.
	MOV X0, #1                 // First argument to write: STDOUT_FILENO
	ADR X1, predictions        // Second argument: ptr to string we want to write
	MOV X2, #13                // Third argument: the label is 13 chars long
	BL _write                  // Print the label to stdout

	// We now do a for loop, with i going from 0 to 2; each time, we will predict
	// on a different example and print the predictions to stdout.
	MOV X0, #0                 // int i = 0;
	STR X0, [SP, #72]          // Store this value of i on stack for later
for_examples:
	CMP X0, #3                 // i < 3?
	B.GE end_for               // if not, exit the loop

	// We first compute the network's prediction on the i-th example by running
	// a forward pass through the network
	LSL X0, X0, #5             // Convert the index to a memory offset
	ADR X1, examples           // Get address of examples[0] in X1
	ADD X1, X1, X0             // Now X1 points to the start of examples[i]
	ADD X0, SP, #8             // First arg to nn_forward: ptr to loaded net
	BL _nn_forward             // Run nn_forward on examples[i]

	// The network's prediction is now in D0. We convert this floating point
	// value to a string with dtoa as we did in demo1 to print it out.
	ADD X0, SP, #80            // First argument to dtoa: pointer to buffer
	MOV X1, #10                // Third argument: again 10 decimals of precision
	BL _dtoa                   // Convert the network's output to printable string

	// We've stringified the network's output to a string held in buffer; we call
	// write to actually print that string to stdout.
	MOV X2, X0                 // Third argument to write: length of string
	MOV X0, #1                 // First argument: STDOUT_FILENO
	ADD X1, SP, #80            // Second argument: buffer to print from
	BL _write                  // Print the network's prediction for i-th example

	// So that the prediction for the next example starts on a new line, we print
	// a newline character.
	MOV X0, #1                 // First argument: STDOUT_FILENO
	ADR X1, predictions        // Get the address of the "Predictions:\n" string
	ADD X1, X1, #12            // and skip past everything but the newline char
	MOV X2, #1                 // We only want to print this single char out
	BL _write                  // Write a newline to stdout

	// We have now finished computing a prediction for the example and then
	// printing it out; we loop for all other examples.
	LDR X0, [SP, #72]          // Get value of i back out of the stack
	ADD X0, X0, #1             // increment it: i++;
	STR X0, [SP, #72]          // Store incremented value back into the stack
	B for_examples             // Loop back to the condition

// At this point, we are fully done with the demo, so we return.
end_for:
	MOV X0, #0                 // We will exit with normal status (0)
	LDR LR, [SP]               // Load the correct return address back into LR
	ADD SP, SP, #112           // Deallocate stack space
	RET                        // return 0;

// These are the examples with unknown label that we will be predicting using
// a pre-trained network. The first example has true label 0, the second
// example has true label 1, and the third example has true label 2.
// (Of course, this is not known to the network; we are asking it to make
// predictions)
examples:
	.quad 5.8, 4.0, 1.2, 0.2        // True label is 0
	.quad 5.5, 2.4, 3.8, 1.1        // True label is 1
	.quad 7.9, 3.8, 6.4, 2.0        // True label is 2

load_path: .asciz "demo.nn"
predictions: .ascii "Predictions:\n"
